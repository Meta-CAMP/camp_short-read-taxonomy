'''Workflow for the CAMP short read taxonomy module.'''


from contextlib import redirect_stderr
import os
from os import makedirs
from os.path import basename, join
import pandas as pd
from utils import Workflow_Dirs, ingest_samples, estimate_read_length


# Load and/or make the working directory structure
dirs = Workflow_Dirs(config['work_dir'], "short-read-taxonomy")


# Load sample names and input files 
SAMPLES = ingest_samples(config['samples'], dirs.TMP)
classifier = config['classification_method']

# --- Workflow output --- #

rule all:
    input:
        join(dirs.OUT, 'samples.csv')

# --- Workflow steps --- #

#if config['mask']==True:
    # create new sample names 

#    rule mask_reads:
#        # Corresponds to map_sort from camp_binning
#        input:
#            fwd = join(dirs.TMP,'{sample}_1.fastq'),
#            rev = join(dirs.TMP,'{sample}_2.fastq')
 #       output:
 #           join(dirs.OUT,'kraken2','{sample}_masked_1.fastq'),
 #           join(dirs.OUT,'kraken2','{sample}.kreport')
 #       log:
 #           join(dirs.LOG, 'kraken2', '{sample}.out'),
 #       params:
 #           kthreads=config['kraken_threads'],
 #           basename=join(dirs.OUT,'kraken2','{sample}'),
 #       shell:
 #           """
 #           kraken2 --db /home/cem2009/ReferenceFiles/kraken2/databases/humanmicroorg --threads {params.kthreads} --report {params.basename}.kreport --output {params.basename}.kraken --paired {input.fwd} {input.rev}
    #        """      

if classifier == 'MetaPhlAn3':
    rule MetaPhlAn3:
        # Corresponds to map_sort from camp_binning
        input:
            fwd = join(dirs.TMP,'{sample}_1.fastq'),
            rev = join(dirs.TMP,'{sample}_2.fastq')
        output:
            join(dirs.OUT,'kraken2','{sample}.kraken'),
        log:
            join(dirs.LOG, 'MetaPhlAn3', '{sample}.out'),
        params:
            taxthreads=config['taxthreads'],
            basename=join(dirs.OUT,'MetaPhlAn3','{sample}'),
            database=config['MetaPhlAn3_database_location']
        shell:
            """
            metaphlan --bowtie2db {params.database} {input.fwd} {input.rev}
            """    

    rule merge_MetaPhlAn3_outputs:
        # Corresponds to map_sort from camp_binning
        input:
            metaphlan_output = join(dirs.OUT,'MetaPhlAn3','{sample}','XXX'),
        output:
            join(dirs.OUT,'MetaPhlAn3','{sample}','MetaPhlAn3_merged.tsv'),
        log:
            join(dirs.LOG, 'MetaPhlAn3', '{sample}.merge.log.out'),
        params:
            basename=join(dirs.OUT,'kraken2','{sample}'),
        shell:
            """
            XXX
            """    

    rule make_config:
        input:
           mergedfile = join(dirs.OUT,'MetaPhlAn3','MetaPhlAn3_merged.tsv')
        output:
            join(dirs.OUT, 'samples.csv')
        run:
            out = []
            out.append(['all_samples',mergedfile])
            df = pd.DataFrame(out)
            df.columns = ['sample_ID','merged_output']
            df.to_csv(str(output), index = False)

if classifier == 'kraken2':
    rule run_kraken2:
        # Corresponds to map_sort from camp_binning
        input:
            fwd = join(dirs.TMP,'{sample}_1.fastq'),
            rev = join(dirs.TMP,'{sample}_2.fastq')
        output:
            join(dirs.OUT,'kraken2','{sample}.kraken'),
            join(dirs.OUT,'kraken2','{sample}.kreport')
        log:
            join(dirs.LOG, 'kraken2', '{sample}.out'),
        threads: config['taxthreads']
        params:
            taxthreads=config['taxthreads'],
            basename=join(dirs.OUT,'kraken2','{sample}'),
            database=config['kraken_bracken_database_location']
        shell:
            """
            kraken2 --db {params.database} --threads {params.taxthreads} --report {params.basename}.kreport --output {params.basename}.kraken --paired {input.fwd} {input.rev}
            """    

    rule run_bracken:
        # Corresponds to map_sort from camp_binning
        input:
            kreport = join(dirs.OUT,'kraken2','{sample}.kreport')
        output:
            join(dirs.OUT,'bracken','{sample}.species.bracken'),
            join(dirs.OUT,'bracken','{sample}.genus.bracken'),
            join(dirs.OUT,'bracken','{sample}.family.bracken'),
            join(dirs.OUT,'bracken','{sample}.order.bracken'),
            join(dirs.OUT,'bracken','{sample}.class.bracken'),
            join(dirs.OUT,'bracken','{sample}.phylum.bracken'),
        log:
            join(dirs.LOG, 'bracken', '{sample}.out'),
        params:
            basename=join(dirs.OUT,'bracken','{sample}'),
            bracken_readlength=config['bracken_readlength'],
            database=config['kraken_bracken_database_location']
        shell:
                """
                bracken -r {params.bracken_readlength} -d {params.database}  -l S -i {input.kreport} -o {params.basename}.species.bracken
                bracken -r {params.bracken_readlength} -d {params.database}  -l G -i {input.kreport} -o {params.basename}.genus.bracken
                bracken -r {params.bracken_readlength} -d {params.database}  -l F -i {input.kreport} -o {params.basename}.family.bracken
                bracken -r {params.bracken_readlength} -d {params.database}  -l O -i {input.kreport} -o {params.basename}.order.bracken
                bracken -r {params.bracken_readlength} -d {params.database}  -l C -i {input.kreport} -o {params.basename}.class.bracken
                bracken -r {params.bracken_readlength} -d {params.database} -l P -i {input.kreport} -o {params.basename}.phylum.bracken
                ### MERGE BRACKEN REPORTS
                """

    rule make_config:
        input:
            expand(join(dirs.OUT,'bracken','{sample}.species.bracken'), sample = SAMPLES)
        output:
            join(dirs.OUT,'samples.csv')
        run:
            out = []
            for i in input:
                out.append([i.split('/')[-1].split('.species.bracken')[0],i.replace('.species.bracken','.kraken'),i.replace('.species.bracken','.kreport'),i,i.replace('.species.bracken','.genus.bracken'),i.replace('.species.bracken','.family.bracken'),i.replace('.species.bracken','.order.bracken'),i.replace('.species.bracken','.class.bracken'),i.replace('.species.bracken','.phylum.bracken')])
                df = pd.DataFrame(out)
                df.columns = ['sample_ID','kraken2_output','kraken2_report','species.bracken','genus.bracken','family.bracken','order.bracken','class.bracken','phylum.bracken']
            df.to_csv(str(output), index = False)


