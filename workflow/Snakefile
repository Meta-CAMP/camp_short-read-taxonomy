'''Workflow for the CAMP short read taxonomy module.'''


from contextlib import redirect_stderr
import os
from os import makedirs
from os.path import basename, join
import pandas as pd
from utils import Workflow_Dirs, ingest_samples, estimate_read_length


# Load and/or make the working directory structure
dirs = Workflow_Dirs(config['work_dir'], "short-read-taxonomy")


# Load sample names and input files 
SAMPLES = ingest_samples(config['samples'], dirs.TMP)
    
# --- Workflow output --- #


rule all:
    input:
        join(dirs.OUT, 'samples.csv')


# --- Workflow steps --- #

if config['mask']==True:
    # create new sample names 
    
    rule mask_reads:
        # Corresponds to map_sort from camp_binning
        input:
            fwd = join(dirs.TMP,'{sample}_1.fastq'),
            rev = join(dirs.TMP,'{sample}_2.fastq')
        output:
            join(dirs.OUT,'kraken2','{sample}.kraken'),
            join(dirs.OUT,'kraken2','{sample}.kreport')
        log:
            join(dirs.LOG, 'kraken2', '{sample}.out'),
        params:
            kthreads=config['kraken_threads'],
            basename=join(dirs.OUT,'kraken2','{sample}'),
        shell:
            """
            kraken2 --db /home/cem2009/ReferenceFiles/kraken2/databases/humanmicroorg --threads {params.kthreads} --report {params.basename}.kreport --output {params.basename}.kraken --paired {input.fwd} {input.rev}
            """      

rule run_kraken2:
    # Corresponds to map_sort from camp_binning
    input:
        fwd = join(dirs.TMP,'{sample}_1.fastq'),
        rev = join(dirs.TMP,'{sample}_2.fastq')
    output:
        join(dirs.OUT,'kraken2','{sample}.kraken'),
        join(dirs.OUT,'kraken2','{sample}.kreport')
    log:
        join(dirs.LOG, 'kraken2', '{sample}.out'),
    params:
        kthreads=config['kraken_threads'],
        basename=join(dirs.OUT,'kraken2','{sample}'),
    shell:
        """
        kraken2 --db /home/cem2009/ReferenceFiles/kraken2/databases/humanmicroorg --threads {params.kthreads} --report {params.basename}.kreport --output {params.basename}.kraken --paired {input.fwd} {input.rev}
        """    

rule run_bracken:
    # Corresponds to map_sort from camp_binning
    input:
        kreport = join(dirs.OUT,'kraken2','{sample}.kreport')
    output:
        join(dirs.OUT,'bracken','{sample}.species.bracken'),
        join(dirs.OUT,'bracken','{sample}.genus.bracken'),
        join(dirs.OUT,'bracken','{sample}.family.bracken'),
        join(dirs.OUT,'bracken','{sample}.order.bracken'),
        join(dirs.OUT,'bracken','{sample}.class.bracken'),
        join(dirs.OUT,'bracken','{sample}.phylum.bracken'),
    log:
        join(dirs.LOG, 'bracken', '{sample}.out'),
    params:
        basename=join(dirs.OUT,'bracken','{sample}'),
        bracken_readlength=config['bracken_readlength']
    shell:
            """
            echo {params.basename}
            bracken -r {params.bracken_readlength} -d /home/cem2009/ReferenceFiles/kraken2/databases/humanmicroorg -l S -i {input.kreport} -o {params.basename}.species.bracken
            bracken -r {params.bracken_readlength} -d /home/cem2009/ReferenceFiles/kraken2/databases/humanmicroorg -l G -i {input.kreport} -o {params.basename}.genus.bracken
            bracken -r {params.bracken_readlength} -d /home/cem2009/ReferenceFiles/kraken2/databases/humanmicroorg -l F -i {input.kreport} -o {params.basename}.family.bracken
            bracken -r {params.bracken_readlength} -d /home/cem2009/ReferenceFiles/kraken2/databases/humanmicroorg -l O -i {input.kreport} -o {params.basename}.order.bracken
            bracken -r {params.bracken_readlength} -d /home/cem2009/ReferenceFiles/kraken2/databases/humanmicroorg -l C -i {input.kreport} -o {params.basename}.class.bracken
            bracken -r {params.bracken_readlength} -d /home/cem2009/ReferenceFiles/kraken2/databases/humanmicroorg -l P -i {input.kreport} -o {params.basename}.phylum.bracken
            """

rule make_config:
    input:
        expand(join(dirs.OUT,'bracken','{sample}.species.bracken'), sample = SAMPLES)
    output:
        join(dirs.OUT, 'samples.csv')
    run:
        out = []
        for i in input:
            out.append([i.split('/')[-1].split('.species.bracken')[0],i.replace('.species.bracken','.kraken'),i.replace('.species.bracken','.kreport'),i,i.replace('.species.bracken','.genus.bracken'),i.replace('.species.bracken','.family.bracken'),i.replace('.species.bracken','.order.bracken'),i.replace('.species.bracken','.class.bracken'),i.replace('.species.bracken','.phylum.bracken')])
            df = pd.DataFrame(out)
            df.columns = ['sample_ID','kraken2_output','kraken2_report','species.bracken','genus.bracken','family.bracken','order.bracken','class.bracken','phylum.bracken']
        df.to_csv(str(output), index = False)






































