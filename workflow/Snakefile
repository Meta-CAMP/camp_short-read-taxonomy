'''Workflow for the CAMP short read taxonomy module.'''


from contextlib import redirect_stderr
import os
from os import makedirs
from os.path import basename, join
import pandas as pd
from utils import Workflow_Dirs, ingest_samples, estimate_read_length


# Load and/or make the working directory structure
dirs = Workflow_Dirs(config['work_dir'], "short-read-taxonomy")


# Load sample names and input files 
SAMPLES = ingest_samples(config['samples'], dirs.TMP)
classifier = config['classification_method']

# --- Workflow output --- #

rule all:
    input:
        join(dirs.OUT, 'samples.csv')

# --- Workflow steps --- #

#if config['mask']==True:
    # create new sample names 

#    rule mask_reads:
#        # Corresponds to map_sort from camp_binning
#        input:
#            fwd = join(dirs.TMP,'{sample}_1.fastq'),
#            rev = join(dirs.TMP,'{sample}_2.fastq')
 #       output:
 #           join(dirs.OUT,'kraken2','{sample}_masked_1.fastq'),
 #           join(dirs.OUT,'kraken2','{sample}.kreport')
 #       log:
 #           join(dirs.LOG, 'kraken2', '{sample}.out'),
 #       params:
 #           kthreads=config['kraken_threads'],
 #           basename=join(dirs.OUT,'kraken2','{sample}'),
 #       shell:
 #           """
 #           kraken2 --db /home/cem2009/ReferenceFiles/kraken2/databases/humanmicroorg --threads {params.kthreads} --report {params.basename}.kreport --output {params.basename}.kraken --paired {input.fwd} {input.rev}
    #        """      

if classifier == 'MetaPhlAn3':
    rule MetaPhlAn3:
        # Corresponds to map_sort from camp_binning
        input:
            fwd = join(dirs.TMP,'{sample}_1.fastq'),
            rev = join(dirs.TMP,'{sample}_2.fastq')
        output:
            join(dirs.OUT,'MetaPhlAn3','{sample}.metaphlan3'),
        log:
            join(dirs.LOG, 'MetaPhlAn3', '{sample}.out'),
        params:
            threads=config['taxthreads'],
            basename=join(dirs.OUT,'MetaPhlAn3','{sample}'),
            database=config['MetaPhlAn3_database_location']
        shell:
            """
            metaphlan --bowtie2db {params.database} {input.fwd} {input.rev}
            """    

    rule merge_MetaPhlAn3_outputs:
        # Corresponds to map_sort from camp_binning
        input:
            metaphlan_output = join(dirs.OUT,'MetaPhlAn3','{sample}','XXX'),
        output:
            join(dirs.OUT,'MetaPhlAn3','{sample}','MetaPhlAn3_merged.tsv'),
        log:
            join(dirs.LOG, 'MetaPhlAn3', '{sample}.merge.log.out'),
        params:
            basename=join(dirs.OUT,'kraken2','{sample}'),
        shell:
            """
            XXX
            """    

    rule make_config:
        input:
           mergedfile = join(dirs.OUT,'MetaPhlAn3','MetaPhlAn3_merged.tsv')
        output:
            join(dirs.OUT, 'samples.csv')
        run:
            out = []
            out.append(['all_samples',mergedfile])
            df = pd.DataFrame(out)
            df.columns = ['sample_ID','merged_output']
            df.to_csv(str(output), index = False)

if classifier == 'kraken2':
    rule run_kraken2:
        # Corresponds to map_sort from camp_binning
        input:
            fwd = join(dirs.TMP,'{sample}_1.fastq'),
            rev = join(dirs.TMP,'{sample}_2.fastq')
        output:
            join(dirs.OUT,'kraken2','{sample}.kraken'),
            join(dirs.OUT,'kraken2','{sample}.kreport')
        log:
            join(dirs.LOG, 'kraken2', '{sample}.out'),
        threads: config['taxthreads']
        params:
            basename=join(dirs.OUT,'kraken2','{sample}'),
            database=config['kraken_bracken_database_location']
        shell:
            """
            kraken2 --db {params.database} --threads {threads} --report {params.basename}.kreport --output {params.basename}.kraken --paired {input.fwd} {input.rev}
            """    

    rule run_bracken:
        input:
            kreport = join(dirs.OUT,'kraken2','{sample}.kreport')
        output:
            join(dirs.OUT,'bracken','{sample}.species.bracken'),
            join(dirs.OUT,'bracken','{sample}.genus.bracken'),
            join(dirs.OUT,'bracken','{sample}.family.bracken'),
            join(dirs.OUT,'bracken','{sample}.order.bracken'),
            join(dirs.OUT,'bracken','{sample}.class.bracken'),
            join(dirs.OUT,'bracken','{sample}.phylum.bracken'),
        log:
            join(dirs.LOG, 'bracken', '{sample}.out'),
        params:
            basename=join(dirs.OUT,'bracken','{sample}'),
            bracken_readlength=config['bracken_readlength'],
            database=config['kraken_bracken_database_location']
        shell:
            """
            bracken -r {params.bracken_readlength} -d {params.database}  -l S -i {input.kreport} -o {params.basename}.species.bracken
            bracken -r {params.bracken_readlength} -d {params.database}  -l G -i {input.kreport} -o {params.basename}.genus.bracken
            bracken -r {params.bracken_readlength} -d {params.database}  -l F -i {input.kreport} -o {params.basename}.family.bracken
            bracken -r {params.bracken_readlength} -d {params.database}  -l O -i {input.kreport} -o {params.basename}.order.bracken
            bracken -r {params.bracken_readlength} -d {params.database}  -l C -i {input.kreport} -o {params.basename}.class.bracken
            bracken -r {params.bracken_readlength} -d {params.database} -l P -i {input.kreport} -o {params.basename}.phylum.bracken
            """

    rule combine_bracken:
        input:
            speciesfiles = expand(join(dirs.OUT,'bracken','{sample}.species.bracken'),sample = SAMPLES),
            genusfiles = expand(join(dirs.OUT,'bracken','{sample}.genus.bracken'),sample = SAMPLES),
            familyfiles = expand(join(dirs.OUT,'bracken','{sample}.family.bracken'),sample = SAMPLES),
            orderfiles = expand(join(dirs.OUT,'bracken','{sample}.order.bracken'),sample = SAMPLES),
            classfiles = expand(join(dirs.OUT,'bracken','{sample}.class.bracken'),sample = SAMPLES),
            phylumfiles = expand(join(dirs.OUT,'bracken','{sample}.phylum.bracken'),sample = SAMPLES),
        output:
            join(dirs.OUT,'bracken','merged','merged.species.bracken.tsv'),
            join(dirs.OUT,'bracken','merged','merged.genus.bracken.tsv'),
            join(dirs.OUT,'bracken','merged','merged.family.bracken.tsv'),
            join(dirs.OUT,'bracken','merged','merged.order.bracken.tsv'),
            join(dirs.OUT,'bracken','merged','merged.class.bracken.tsv'),
            join(dirs.OUT,'bracken','merged','merged.phylum.bracken.tsv'),
        params:
            brack_loc=join(dirs.OUT,'bracken'),
        shell:
            """
            python2 scripts/combine_bracken_outputs.py --files {input.speciesfiles} -o {params.brack_loc}/merged/merged.species.bracken.tsv
            python2 scripts/combine_bracken_outputs.py --files {input.genusfiles} -o {params.brack_loc}/merged/merged.genus.bracken.tsv
            python2 scripts/combine_bracken_outputs.py --files {input.familyfiles} -o {params.brack_loc}/merged/merged.family.bracken.tsv
            python2 scripts/combine_bracken_outputs.py --files {input.orderfiles} -o {params.brack_loc}/merged/merged.order.bracken.tsv
            python2 scripts/combine_bracken_outputs.py --files {input.classfiles} -o {params.brack_loc}/merged/merged.class.bracken.tsv
            python2 scripts/combine_bracken_outputs.py --files {input.phylumfiles} -o {params.brack_loc}/merged/merged.phylum.bracken.tsv
            """

    rule make_config:
        input:
            join(dirs.OUT,'bracken','merged','merged.species.bracken.tsv'),
            join(dirs.OUT,'bracken','merged','merged.genus.bracken.tsv'),
            join(dirs.OUT,'bracken','merged','merged.family.bracken.tsv'),
            join(dirs.OUT,'bracken','merged','merged.order.bracken.tsv'),
            join(dirs.OUT,'bracken','merged','merged.class.bracken.tsv'),
            join(dirs.OUT,'bracken','merged','merged.phylum.bracken.tsv'),
        output:
            join(dirs.OUT,'samples.csv')
        run:
            out = []
            for i in input:
                level=i.split('.')[1]
                out.append([level,i])
            df = pd.DataFrame(out)
            df.columns = ['taxlevel','location']
            df.to_csv(str(output), index = False)


