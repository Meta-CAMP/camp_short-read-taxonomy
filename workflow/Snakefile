'''Workflow for the CAMP short read taxonomy module.'''


from contextlib import redirect_stderr
import os
from os import makedirs
from os.path import basename, join
import pandas as pd
from utils import Workflow_Dirs, ingest_samples, estimate_read_length


# Load and/or make the working directory structure
dirs = Workflow_Dirs(config['work_dir'], "short-read-taxonomy")


# Load sample names and input files 
SAMPLES = ingest_samples(config['samples'], dirs.TMP)

# --- Workflow output --- #


def workflow_mode(wildcards):
	if bool(config['mask'])==True:
		fwd = join(dirs.TMP,'{sample}_1.masked.fastq.gz')
		rev = join(dirs.TMP,'{sample}_2.masked.fastq.gz')
		return [fwd,rev]
	else:
		fwd = join(dirs.TMP,'{sample}_1.fastq.gz')
		rev = join(dirs.TMP,'{sample}_2.fastq.gz')
		return [fwd,rev]


def workflow_output(wildcards):
	outputlist = []
	if bool(config['MetaPhlAn3']):
		outputlist.append(join(dirs.OUT,'MetaPhlAn3','MetaPhlAn3_merged.tsv'))
	if bool(config['kraken2']):
		outputlist.extend([join(dirs.OUT,'bracken','merged','merged.species.bracken.tsv'),join(dirs.OUT,'bracken','merged','merged.genus.bracken.tsv'),join(dirs.OUT,'bracken','merged','merged.family.bracken.tsv'),join(dirs.OUT,'bracken','merged','merged.order.bracken.tsv'),join(dirs.OUT,'bracken','merged','merged.class.bracken.tsv'),join(dirs.OUT,'bracken','merged','merged.phylum.bracken.tsv')])
	if bool(config['xtree_bacterial_archaeal']):
		outputlist.extend([join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_counts.tsv'),join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_counts_raw.tsv'),join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_ra.tsv'),join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_ra_raw.tsv'),join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_coverages.tsv'),join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_unique_coverages.tsv')])
	if bool(config['xtree_viral']):	
		outputlist.extend([join(dirs.OUT,'xtree_merged','xtree_viral_counts.tsv'),join(dirs.OUT,'xtree_merged','xtree_viral_counts_raw.tsv'),join(dirs.OUT,'xtree_merged','xtree_viral_ra.tsv'),join(dirs.OUT,'xtree_merged','xtree_viral_ra_raw.tsv'),join(dirs.OUT,'xtree_merged','xtree_viral_coverages.tsv'),join(dirs.OUT,'xtree_merged','xtree_viral_unique_coverages.tsv')])
	if bool(config['xtree_fungi_protozoa']):		
		outputlist.extend([join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_counts.tsv'),join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_counts_raw.tsv'),join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_ra.tsv'),join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_ra_raw.tsv'),join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_coverages.tsv'),join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_unique_coverages.tsv')])
	return(outputlist)

rule all:
	input:
		join(dirs.OUT, 'samples.csv')

# --- Workflow steps --- #

rule mask_reads:
	input:
		fwd = join(dirs.TMP,'{sample}_1.fastq.gz'),
		rev = join(dirs.TMP,'{sample}_2.fastq.gz')
	output:
		join(dirs.TMP,'{sample}_1.masked.fastq.gz'),
		join(dirs.TMP,'{sample}_2.masked.fastq.gz')
	log:
		join(dirs.LOG, 'masking', '{sample}.out'),
	threads:
		config['taxthreads']
	params:
		outfwd = join(dirs.TMP,'{sample}_1.masked.fastq.gz'),
		outrev = join(dirs.TMP,'{sample}_2.masked.fastq.gz')
	shell:
		"""
		bbmask.sh in={input.fwd} out={params.outfwd} overwrite=t threads={threads}
		bbmask.sh in={input.rev} out={params.outrev} overwrite=t threads={threads}
		"""      

rule MetaPhlAn3:
	input:
		inputfiles=workflow_mode,
	output:
		join(dirs.OUT,'MetaPhlAn3','raw_output','{sample}.metaphlan3'),
	log:
		join(dirs.LOG, 'MetaPhlAn3', '{sample}.out'),
	threads:
		config['taxthreads']
	params:
		basename=join(dirs.OUT,'MetaPhlAn3','raw_output','{sample}'),
		basenametmp=join(dirs.TMP,'{sample}'),
		database=config['MetaPhlAn3_database_location'],
	shell:
		"""
		metaphlan --bowtie2db {params.database} --input_type fastq --force  -o {params.basename}.metaphlan3 --bowtie2out {params.basenametmp}.bowtie2.bz2 $(echo {input.inputfiles} | sed 's/ /,/g')
		"""    

rule merge_MetaPhlAn3_outputs:
	input:
		metaphlanouts = expand(join(dirs.OUT,'MetaPhlAn3','raw_output','{sample}.metaphlan3'),sample = SAMPLES),
	output:
		join(dirs.OUT,'MetaPhlAn3','MetaPhlAn3_merged.tsv'),
	log:
		join(dirs.LOG, 'MetaPhlAn3', 'merge.log.out'),
	params:
		outfile = join(dirs.OUT,'MetaPhlAn3','MetaPhlAn3_merged.tsv'),
	shell:
		"""
		merge_metaphlan_tables.py {input.metaphlanouts} > {params.outfile}
		"""    

rule run_kraken2:
	input:
		inputfiles=workflow_mode,
	output:
		join(dirs.OUT,'kraken2','{sample}.kraken'),
		join(dirs.OUT,'kraken2','{sample}.kreport')
	log:
		join(dirs.LOG, 'kraken2', '{sample}.out'),
	threads: 
		config['taxthreads']
	params:
		basename=join(dirs.OUT,'kraken2','{sample}'),
		database=config['kraken_bracken_database_location']
	shell:
		"""
		kraken2 --db {params.database} --threads {threads} --report {params.basename}.kreport --output {params.basename}.kraken --paired {input.inputfiles}
		"""    

rule run_bracken:
	input:
		kreport = join(dirs.OUT,'kraken2','{sample}.kreport')
	output:
		join(dirs.OUT,'bracken','{sample}.species.bracken'),
		join(dirs.OUT,'bracken','{sample}.genus.bracken'),
		join(dirs.OUT,'bracken','{sample}.family.bracken'),
		join(dirs.OUT,'bracken','{sample}.order.bracken'),
		join(dirs.OUT,'bracken','{sample}.class.bracken'),
		join(dirs.OUT,'bracken','{sample}.phylum.bracken'),
	log:
		join(dirs.LOG, 'bracken', '{sample}.out'),
	params:
		basename=join(dirs.OUT,'bracken','{sample}'),
		bracken_readlength=config['bracken_readlength'],
		database=config['kraken_bracken_database_location']
	shell:
		"""
		bracken -r {params.bracken_readlength} -d {params.database}  -l S -i {input.kreport} -o {params.basename}.species.bracken
		bracken -r {params.bracken_readlength} -d {params.database}  -l G -i {input.kreport} -o {params.basename}.genus.bracken
		bracken -r {params.bracken_readlength} -d {params.database}  -l F -i {input.kreport} -o {params.basename}.family.bracken
		bracken -r {params.bracken_readlength} -d {params.database}  -l O -i {input.kreport} -o {params.basename}.order.bracken
		bracken -r {params.bracken_readlength} -d {params.database}  -l C -i {input.kreport} -o {params.basename}.class.bracken
		bracken -r {params.bracken_readlength} -d {params.database} -l P -i {input.kreport} -o {params.basename}.phylum.bracken
		"""

rule combine_bracken:
	input:
		speciesfiles = expand(join(dirs.OUT,'bracken','{sample}.species.bracken'),sample = SAMPLES),
		genusfiles = expand(join(dirs.OUT,'bracken','{sample}.genus.bracken'),sample = SAMPLES),
		familyfiles = expand(join(dirs.OUT,'bracken','{sample}.family.bracken'),sample = SAMPLES),
		orderfiles = expand(join(dirs.OUT,'bracken','{sample}.order.bracken'),sample = SAMPLES),
		classfiles = expand(join(dirs.OUT,'bracken','{sample}.class.bracken'),sample = SAMPLES),
		phylumfiles = expand(join(dirs.OUT,'bracken','{sample}.phylum.bracken'),sample = SAMPLES),
	output:
		join(dirs.OUT,'bracken','merged','merged.species.bracken.tsv'),
		join(dirs.OUT,'bracken','merged','merged.genus.bracken.tsv'),
		join(dirs.OUT,'bracken','merged','merged.family.bracken.tsv'),
		join(dirs.OUT,'bracken','merged','merged.order.bracken.tsv'),
		join(dirs.OUT,'bracken','merged','merged.class.bracken.tsv'),
		join(dirs.OUT,'bracken','merged','merged.phylum.bracken.tsv'),
	params:
		brack_loc=join(dirs.OUT,'bracken'),
	shell:
		"""
		python2 scripts/combine_bracken_outputs.py --files {input.speciesfiles} -o {params.brack_loc}/merged/merged.species.bracken.tsv
		python2 scripts/combine_bracken_outputs.py --files {input.genusfiles} -o {params.brack_loc}/merged/merged.genus.bracken.tsv
		python2 scripts/combine_bracken_outputs.py --files {input.familyfiles} -o {params.brack_loc}/merged/merged.family.bracken.tsv
		python2 scripts/combine_bracken_outputs.py --files {input.orderfiles} -o {params.brack_loc}/merged/merged.order.bracken.tsv
		python2 scripts/combine_bracken_outputs.py --files {input.classfiles} -o {params.brack_loc}/merged/merged.class.bracken.tsv
		python2 scripts/combine_bracken_outputs.py --files {input.phylumfiles} -o {params.brack_loc}/merged/merged.phylum.bracken.tsv
		"""

### SEPARATE THIS INTO THREE MODES AND MERGE THE PARSING RULE INTO EACH OF THEM
### FOR TESTING NEED TO FIND A DIFFERENT MOCK SAMPLE WITH VIRAL DATA, MAYBE ONE OF THOSE SHALLOW ASS LAKE SAMPLES
### CURRENTLY IF YOU ONLY RUN ONE SAMPLE THROUGH THE PARSING SCRIPT BREAKS...

rule run_xtree_bacterial:
	input:
		inputfiles=workflow_mode,
	output:
		join(dirs.OUT,'xtree_bacteria','{sample}.ref'),
		join(dirs.OUT,'xtree_bacteria','{sample}.cov'),
	log:
		join(dirs.LOG, 'xtree', '{sample}.out'),
	threads: 
		config['taxthreads']
	params:
		basename_b=join(dirs.OUT,'xtree_bacteria','{sample}'),
		bactarcdb=config['xtree_gtdb_database_location'],
		xtree_executable=config['xtree_executable'],
	shell:
		"""
		cat {input.inputfiles} | {params.xtree_executable} --seqs - --threads {threads} --db {params.bactarcdb} --ref-out {params.basename_b}.ref --cov-out {params.basename_b}.cov --redistribute
		"""    

rule run_xtree_viral:
	input:
		inputfiles=workflow_mode,
	output:
		join(dirs.OUT,'xtree_viral','{sample}.ref'),
		join(dirs.OUT,'xtree_viral','{sample}.cov'),
	log:
		join(dirs.LOG, 'xtree', '{sample}.out'),
	threads: 
		config['taxthreads']
	params:
		basename_v=join(dirs.OUT,'xtree_viral','{sample}'),
		viraldb=config['xtree_viral_database_location'],
		xtree_executable=config['xtree_executable'],
	shell:
		"""
		cat {input.inputfiles} | {params.xtree_executable} --seqs - --threads {threads} --db {params.viraldb} --ref-out {params.basename_v}.ref --cov-out {params.basename_v}.cov --redistribute
		"""    

rule run_xtree_fungi_protozoa:
	input:
		inputfiles=workflow_mode,
	output:
		join(dirs.OUT,'xtree_protozoa_fungi','{sample}.ref'),
		join(dirs.OUT,'xtree_protozoa_fungi','{sample}.cov'),
	log:
		join(dirs.LOG, 'xtree', '{sample}.out'),
	threads: 
		config['taxthreads']
	params:
		basename_fp=join(dirs.OUT,'xtree_protozoa_fungi','{sample}'),
		protfundb=config['xtree_fungiprotozoa_database_location'],
		xtree_executable=config['xtree_executable'],
	shell:
		"""
		cat {input.inputfiles} | {params.xtree_executable} --seqs - --threads {threads} --db {params.protfundb} --ref-out {params.basename_fp}.ref --cov-out {params.basename_fp}.cov --redistribute
		"""    

rule parse_xtree_output_bacarc:
	input:
		expand(join(dirs.OUT,'xtree_bacteria','{sample}.cov'),sample=SAMPLES),
		expand(join(dirs.OUT,'xtree_viral','{sample}.cov'),sample=SAMPLES),
		expand(join(dirs.OUT,'xtree_protozoa_fungi','{sample}.cov'),sample=SAMPLES),
	output:
		join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_counts.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_counts_raw.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_ra.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_ra_raw.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_coverages.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_bacterial_archaeal_unique_coverages.tsv'),
	log:
		join(dirs.LOG, 'xtree', 'merging.out'),
	threads: 
		config['taxthreads'],
	params:
		outdir = join(dirs.OUT,'xtree_merged'),
		xtree_bac = join(dirs.OUT,'xtree_bacteria'),
		hthresh_bac = config['hthresh_bac'],
		uthresh_bac = config['uthresh_bac'],
		thresh_bac = config['thresh_bac'],
		mappingfile_loc = config['mappingfile_loc']
	shell: 
		"""
		Rscript scripts/post_process_xtree.R {params.xtree_bac} {params.thresh_bac} {params.hthresh_bac} {params.uthresh_bac} {params.outdir} bacterial_archaeal {params.mappingfile_loc}
		"""

rule parse_xtree_output_viral:
	input:
		expand(join(dirs.OUT,'xtree_viral','{sample}.cov'),sample=SAMPLES),
	output:
		join(dirs.OUT,'xtree_merged','xtree_viral_counts.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_viral_counts_raw.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_viral_ra.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_viral_ra_raw.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_viral_coverages.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_viral_unique_coverages.tsv'),
	log:
		join(dirs.LOG, 'xtree', 'merging.out'),
	threads: 
		config['taxthreads'],
	params:
		outdir = join(dirs.OUT,'xtree_merged'),
		xtree_viral = join(dirs.OUT,'xtree_viral'),
		hthresh_viral = config['hthresh_viral'],
		uthresh_viral = config['uthresh_viral'],
		thresh_viral = config['thresh_viral'],
		mappingfile_loc = config['mappingfile_loc']
	shell: 
		"""
		Rscript scripts/post_process_xtree.R {params.xtree_viral} {params.thresh_viral} {params.hthresh_viral} {params.uthresh_viral} {params.outdir} viral {params.mappingfile_loc}
		"""


rule parse_xtree_output_funprot:
	input:
		expand(join(dirs.OUT,'xtree_protozoa_fungi','{sample}.cov'),sample=SAMPLES),
	output:
		join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_counts.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_counts_raw.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_ra.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_ra_raw.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_coverages.tsv'),
		join(dirs.OUT,'xtree_merged','xtree_protozoa_fungi_unique_coverages.tsv'),
	log:
		join(dirs.LOG, 'xtree', 'merging.out'),
	threads: 
		config['taxthreads'],
	params:
		outdir = join(dirs.OUT,'xtree_merged'),
		xtree_protozoafungi = join(dirs.OUT,'xtree_protozoa_fungi'),
		hthresh_fungprot = config['hthresh_fungprot'],
		uthresh_fungprot = config['uthresh_fungprot'],
		thresh_fungprot = config['thresh_fungprot'],
		mappingfile_loc = config['mappingfile_loc']
	shell: 
		"""
		Rscript scripts/post_process_xtree.R {params.xtree_protozoafungi} {params.thresh_fungprot} {params.hthresh_fungprot} {params.uthresh_fungprot} {params.outdir} protozoa_fungi {params.mappingfile_loc}
		"""

rule make_config:
	input:
		workflow_output
	output:
		join(dirs.OUT,'samples.csv')
	run:
		out = []
		for i in input:
			if 'MetaPhlAn3' in i:
				classifiertype='MetaPhlAn3'
			if 'bracken' in i:
				classifiertype='kraken2'
			if 'xtree' in i:
				classifiertype='xtree'
			out.append([classifiertype,i,config['mask']])
		df = pd.DataFrame(out)
		df.columns = ['classifier_type','location','mask_status']
		df.to_csv(str(output), index = False)





